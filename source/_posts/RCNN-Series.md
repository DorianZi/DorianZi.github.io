---
title: RCNN Series 用于目标检测的RCNN系列网络
date: 2019-05-26 09:11:38
tags: ["Computer Vision"]
categories: Technic
---

首先我们看我们要实现的什么：

![](/uploads/RCNN_1.png)

我们要实现图3的Object Detection.不仅需要将物体识别出来还需要画出它们的位置。我们知道将物体识别，通过CNN是可以实现的，那么这里关键的部分就是定位了。基于CNN和定位的思想，算法界出现了RCNN，即Region Convolution Neural Network.  之后，基于RCNN，相继出现了改进的算法：Fast RCNN, Faster RCNN, Mask RCNN.

本文将逐一讲解以上算法。

# RCNN

RCNN的流程图如下：

![](/uploads/RCNN_2.png)

它的预测流程是：

1）使用[Selective Search](https://zhuanlan.zhihu.com/p/39927488)方法选中proposal框
![](/uploads/RCNN_3.png)

2）将选出来的proposal框们resize到固定大小，然后分别通过CNN（比如AlexNet）识别器。不过这不是完全的CNN网络，而是走到全连接之前获得了4096个特征就停止。

这是完整的CNN网络：
![](/uploads/RCNN_4.png)

这是中间停止的：
![](/uploads/RCNN_5.png)

可以看到在第5个池化之后，我们已经获取了4096个特征。
如果图片一共有2000个proposal框，那么经过这一步骤之后我们得到了一个2000\*4096的特征矩阵

3）将每个proposal框的4096个特征分别经过20个SVM二分类器（每个分类器有4096个系数）进行物体识别分类
这个过程可以用2000\*4096的矩阵和4096\*20的矩阵相乘来表示，求得一个2000\*20的矩阵。这个矩阵每一行表示某个proposal框在是各种类别的打分（或者概率）。

4) 使用非极大抑制方法来去除无用的框。
所谓无用的框是因为2000个proposal框中其实只有很少的框是最终需要留下来的。这里的非极大抑制方法是保留（想象上面2000\*20矩阵中的每一个元素）打分最高的框，同时与该框框重叠度（称作IOU）超过设定阈值（比如0.6）的框被删除。它的思想是抑制局部非最大的，保留局部极值

![](/uploads/RCNN_6.png)

这种方法之所以有效是因为：首先打分最高的框是可能框得最合理的（因为我们相信CNN识别器的准确度），而与该框重叠度比较高的框很可能是框柱了该物体的很大一部分，却框偏了的。

可以思考一种实际情况：当图片里面有两只猫在不同的位置。这时候，在“猫”的这个分类下面，会有两个框被保留下来，因为尽管这两个框的打分有大有小，但是它们的IOU是远小于阈值（比如0.6）的。

另一种实际情况是：如果待识别的图片里面只有一只猫（虽然选出了很多个proposal框），而SVM分类器有猫、狗、鱼等20个类别。那么这些proposal框中会有非常多的框在任何分类下的打分都是非常低。如果根据非极大抑制方法，那么在“狗”这个分类下会保留至少一个框，这是不符合要求的。可见，非极大抑制还需要设置打分阈值，即不是所有局部极值都能保留，如果没有到达打分阈值，该类别下所有值都可能被删除。

5）将留下来的框，通过回归器来进行位置微调
每个类别会有4个被训练好的回归器，分别用来回归4个值：框的左上顶点的x坐标，y坐标，框的宽，框的高。每个类别都有，意思是比如猫有猫的框位置回归器4个，狗也有狗的4个。按类别分的思想是：系统认为框柱一只胖猫和一只很高的长颈鹿，用的框是不一样的。

至此一次目标检测就完成了。

# 三个模型
在RCNN中有三个独立的部分：CNN识别器，SVM分类器，位置回归器。

## CNN识别器
这个CNN不是完全的CNN，而是做了fine-tuning。具体构建如下：

首先使用ImageNet数据进行训练或者找到一个现成的通用的CNN物体识别器，它有识别1000种物体的能力：

![](/uploads/RCNN_7.png)

我们需要它是因为，它含有训练好的具有强大识别能力的参数。

接着做一个[迁移学习](https://zh.wikipedia.org/zh-hans/%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0)网络。截掉softmax和改动了最后一个全连接层，且将最后一个全连接从4096\*1000  更改为4096\*21，再次训练这个新的21类识别器网络。这么做是为了利用1000类识别器已经训练好的强大参数作为初始值。

![](/uploads/RCNN_8.png)

注意，训练该21类分类器时，使用的数据是用于目标检测的数据库，也就是人为标注了框，带有类别标签的图片。确切地说，是被框出来的那些图像。之所以如此，是因为我们终究需要它适应目标检测的图片，而不是ImageNet数据库里的广义图像。

不过等等，我们可以用一种类似数据增强的方法：使用selective search之后proposal框出来的图像，而不是作为label的框出来的图像。把与label框的IOU大于0.5的proposal框图像抠出来作为数据，把label作为它的label；把与label框的IOU小于0.5的proposal框图像抠出来作为数据，把“背景”作为它的label。这样我们就充分利用了大量的selective search出来的图像。

值得一提的是，这里训练出来的21类识别器仍然没有被用到最后的预测网络中。因为我们要的不是它的21类预测能力，而是它在进行21类预测前所训练出来的提取特征的能力。我们用提取出来的特征，转而用SVM进行21类分类。因为RCNN的作者通过实验得出的结论是SVM的识别率高于全连接加softmax的输出。

## SVM分类器

正如上面所说，SVM分类器的数据来自于被中断的CNN输出，中断点是在全连接之前，第5个池化之后。上面的预测过程中已经给出了图。
SVM的训练数据来自于


# 参考

https://www.cnblogs.com/skyfsm/p/6806246.html
https://zhuanlan.zhihu.com/p/43619815

