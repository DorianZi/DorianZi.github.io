<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
















  <meta name="baidu-site-verification" content="L6qAeUEWrk">











<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.1',
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '6O9OK26379',
      apiKey: 'd266e496228bce82728a87f4c2ea4800',
      indexName: 'MyHexo',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="卷积和神经网络卷积了解卷积神经网络(Convolutional Neural Network)之前先来了解卷积。见下图：  从上图看，一个矩阵被另一个矩阵（我们称作“卷积核”）执行卷积，就是中矩阵通过一定步长（图中步长为1，也就是每次移动一个元素）扫描左矩阵，每次停留时计算对应元素的乘积之和作为新矩阵（右）的元素。 具体的计算例子：  卷积的神经网络表示那么卷积计算如何使用神经网络来构建呢？在之前">
<meta name="keywords" content="Algorithm,Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN 卷积神经网络">
<meta property="og:url" content="https://dorianzi.github.io/2019/04/25/CNN/index.html">
<meta property="og:site_name" content="Dorian Mode">
<meta property="og:description" content="卷积和神经网络卷积了解卷积神经网络(Convolutional Neural Network)之前先来了解卷积。见下图：  从上图看，一个矩阵被另一个矩阵（我们称作“卷积核”）执行卷积，就是中矩阵通过一定步长（图中步长为1，也就是每次移动一个元素）扫描左矩阵，每次停留时计算对应元素的乘积之和作为新矩阵（右）的元素。 具体的计算例子：  卷积的神经网络表示那么卷积计算如何使用神经网络来构建呢？在之前">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_1.gif">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_2.gif">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\begin{bmatrix}&space;1&space;&&space;2&space;&&space;3\\&space;4&space;&&space;5&space;&&space;6\\&space;7&space;&8&space;&9&space;\end{bmatrix}&space;\ast&space;\begin{bmatrix}&space;1&space;&2&space;\\&space;3&space;&&space;4&space;\end{bmatrix}=\begin{bmatrix}&space;37&space;&&space;47\\&space;67&space;&&space;77&space;\end{bmatrix}">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_3.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_4.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_5.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_6.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_7.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_8.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_9.png">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?a_{m+1}=a_m-\eta&space;\Delta">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?a_m">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?a_{m+1}=\gamma&space;a_m-\eta&space;\Delta">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?C=C_0+\frac{\lambda&space;}{2n}\sum_{w}^{&space;}w^2">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;w}=\frac{\partial&space;C_0}{\partial&space;w}+\frac{\lambda&space;}{n}w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\lambda">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?n">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\begin{align*}&space;w_{m+1}&=w_m-\eta&space;\Delta&space;\\&space;&=w_m-\eta&space;(\frac{\partial&space;C_0}{\partial&space;w_m}+\frac{\lambda&space;}{n}w_m)&space;\\&space;&=(1-\frac{\eta&space;\lambda&space;}{n})w_m-\eta&space;\frac{\partial&space;C_0}{\partial&space;w_m}&space;\end{align*}">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?1-\frac{\eta&space;\lambda&space;}{n}">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;b}=\frac{C_0}{b}+0">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?C=C_0+\frac{\lambda&space;}{n}\sum_{w}^{&space;}|w|">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;w}=\frac{\partial&space;C_0}{\partial&space;w}+\frac{\lambda&space;}{n}sgn(w)">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?sgn(w)">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\begin{align*}&space;w_{m+1}&=w_m-\eta&space;\Delta&space;\\&space;&=w_m-\eta&space;(\frac{\partial&space;C_0}{\partial&space;w_m}+\frac{\lambda&space;}{n}sgn(w_m))&space;\\&space;&=w_m-\frac{\eta&space;\lambda&space;}{n}sgn(w_m)-\eta&space;\frac{\partial&space;C_0}{\partial&space;w_m}&space;\end{align*}">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?w">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?\eta">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_10.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_11.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_12.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_13.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_14.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/cnn_15.png">
<meta property="og:updated_time" content="2019-04-30T05:19:02.920Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN 卷积神经网络">
<meta name="twitter:description" content="卷积和神经网络卷积了解卷积神经网络(Convolutional Neural Network)之前先来了解卷积。见下图：  从上图看，一个矩阵被另一个矩阵（我们称作“卷积核”）执行卷积，就是中矩阵通过一定步长（图中步长为1，也就是每次移动一个元素）扫描左矩阵，每次停留时计算对应元素的乘积之和作为新矩阵（右）的元素。 具体的计算例子：  卷积的神经网络表示那么卷积计算如何使用神经网络来构建呢？在之前">
<meta name="twitter:image" content="https://dorianzi.github.io/uploads/cnn_1.gif">






  <link rel="canonical" href="https://dorianzi.github.io/2019/04/25/CNN/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>CNN 卷积神经网络 | Dorian Mode</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?bdd9553b00b737f4e03ff3fc43e220f2";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/DorianZi/DorianZi.github.io/tree/master" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Dorian Mode</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://dorianzi.github.io/2019/04/25/CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dorian Zi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/eric_clapton.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dorian Mode">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CNN 卷积神经网络

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-04-25 23:18:36" itemprop="dateCreated datePublished" datetime="2019-04-25T23:18:36+08:00">2019-04-25</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Technic/" itemprop="url" rel="index"><span itemprop="name">Technic</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             Views:  
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          
          
          <!--Dorian Added Start-->
          
            <div class="post-tags">
              
                <a href="/tags/Algorithm/" <i class="fa fa-tag"> Algorithm</a>
              
                <a href="/tags/Deep-Learning/" <i class="fa fa-tag"> Deep Learning</a>
              
            </div>
          
          <!--Dorian Added End-->
        
        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="卷积和神经网络"><a href="#卷积和神经网络" class="headerlink" title="卷积和神经网络"></a>卷积和神经网络</h1><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p>了解卷积神经网络(Convolutional Neural Network)之前先来了解卷积。见下图：</p>
<p><img src="/uploads/cnn_1.gif" alt></p>
<p>从上图看，一个矩阵被另一个矩阵（我们称作“卷积核”）执行卷积，就是中矩阵通过一定步长（图中步长为1，也就是每次移动一个元素）扫描左矩阵，每次停留时计算对应元素的乘积之和作为新矩阵（右）的元素。</p>
<p>具体的计算例子：</p>
<p><img src="/uploads/cnn_2.gif" alt></p>
<h2 id="卷积的神经网络表示"><a href="#卷积的神经网络表示" class="headerlink" title="卷积的神经网络表示"></a>卷积的神经网络表示</h2><p>那么卷积计算如何使用神经网络来构建呢？在之前的blog里讲过神经网络是加权求和，于是我们可以这么构建：</p>
<p>实现<img src="https://latex.codecogs.com/gif.latex?\begin{bmatrix}&space;1&space;&&space;2&space;&&space;3\\&space;4&space;&&space;5&space;&&space;6\\&space;7&space;&8&space;&9&space;\end{bmatrix}&space;\ast&space;\begin{bmatrix}&space;1&space;&2&space;\\&space;3&space;&&space;4&space;\end{bmatrix}=\begin{bmatrix}&space;37&space;&&space;47\\&space;67&space;&&space;77&space;\end{bmatrix}" title="\begin{bmatrix} 1 & 2 & 3\\ 4 & 5 & 6\\ 7 &8 &9 \end{bmatrix} \ast \begin{bmatrix} 1 &2 \\ 3 & 4 \end{bmatrix}=\begin{bmatrix} 37 & 47\\ 67 & 77 \end{bmatrix}">的神经网络为：</p>
<p><img src="/uploads/cnn_3.png" alt></p>
<h1 id="CNN的各层"><a href="#CNN的各层" class="headerlink" title="CNN的各层"></a>CNN的各层</h1><p>CNN是因为有卷积层才叫CNN，但是除此外通常还有几个层:线性整流层，池化层，全连接层。至于它们的组合顺序和个数，取决于不同网络设计方式。只要它有效，任何组合方式的CNN网络都可以被认可。</p>
<p>我们假设输入为图像，来讲讲常见的构造：卷积层-&gt;线性整流层-&gt;池化层-&gt;全连接层</p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>正如上面的例子讲过的，卷积层是对各个像素进行加权求和，而权重就是卷积核（或称作感受野）的元素。卷积层的物理意义就是提取图像各个部分的特征</p>
<h2 id="线性整流层"><a href="#线性整流层" class="headerlink" title="线性整流层"></a>线性整流层</h2><p>整流层采用激活函数进行激活，常用的是Relu函数，它的图像如下：</p>
<p><img src="/uploads/cnn_4.png" alt></p>
<p>为什么选择Relu? 因为：</p>
<p>1）信号通过它之后等于设置了阈值，在小于阈值（比如小于0），信号完全衰减。换句话说，不是所有信号都去拟合，这样有助于防止过拟合<br>2）它的导数大部分为常数，反向传播时计算量大大减小<br>3）它不像Sigmoid等激活函数，越往后导数越接近于零，容易造成梯度消失。而梯度消失会导致参数没法更新，训练停滞</p>
<p>很多情况下，习惯将线性整流层并入卷积层的。所以在有些文档里，我们不会看到“线性整流层”</p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><p>池化层是为了保留主要的特征，缩减数据量，减少下一层的参数和计算量，防止过拟合。常用的有mean-pooling和max-pooling</p>
<p>2x2平均池化：</p>
<p><img src="/uploads/cnn_5.png" alt></p>
<p>2x2最大池化：</p>
<p><img src="/uploads/cnn_6.png" alt></p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><p>卷积层和池化层都是对局部的操作，而全连接层得以将全局进行加权求和。全连接层常常是放在神经网络的最后一层或接近最后（后面不会再接卷积层了），因为我们轻易不进行全连接，只有最后需要输出预测了才进行全局整合。</p>
<p>另外，这里有一个trick: 我们可以把全连接层理解为特殊的卷积层，即感受野和原矩阵一样大的卷积层！</p>
<h1 id="网络优化"><a href="#网络优化" class="headerlink" title="网络优化"></a>网络优化</h1><p>出了常用layer之外，我们在进行CNN构造或者训练的时候常常会使用一些有效的方法：</p>
<h2 id="Padding"><a href="#Padding" class="headerlink" title="Padding"></a>Padding</h2><p>通常说的Padding是zero-Padding,也就是补零。它是对被卷积图像边缘进行补零扩充的方式。</p>
<p>为什么要补零呢？</p>
<p>因为不补零的话，卷积的结果矩阵的size会比原矩阵缩小（且在stride步长越大的情况下，缩小越厉害），造成信息的损失</p>
<p>为了保持矩阵一致，我们使用zero-Padding。示例如下：</p>
<p><img src="/uploads/cnn_7.png" alt></p>
<h2 id="参数共享"><a href="#参数共享" class="headerlink" title="参数共享"></a>参数共享</h2><p>参数共享指的是，每一层的卷积操作，我们只使用一个卷积核对所有的输入进行操作。我们并不会在移动一个步长之后变换卷积核中的元素值，这样对于该层的权重来说，它是权值共享的。</p>
<p>为什么要参数共享呢？一方面是为了能够减少计算量，另一方面从意义上说，我们可以看做一个卷积核的操作是“一类”特征的提取。我们“公平地”使用同一个卷积核对整张图片的所有部分进行特征提取。</p>
<p>参数共享不代表特征提取就单调了，因为可以再定义一层多层卷积，使用不同的卷积核进行不同的特征提取。</p>
<h1 id="训练优化"><a href="#训练优化" class="headerlink" title="训练优化"></a>训练优化</h1><p>除了网络结构上的优化，在实际训练中也有很多有效的tricks。<br>这里的训练优化已经不是针对于CNN了，在神经网络中有普遍的应用</p>
<h2 id="Dropout"><a href="#Dropout" class="headerlink" title="Dropout"></a>Dropout</h2><p>深度神经网络的普遍问题就是训练时间长和过拟合，为了减少这些问题，Dropout是有效的方法之一。</p>
<p>Dropout是指在训练中基于dropout rate随机丢弃元素，使得网络简化，而且因为每轮训练丢弃的元素不同，所以每轮保留的特征是不同的，这样训练出来的模型范化性更强。示例如下：</p>
<p><img src="/uploads/cnn_8.png" alt></p>
<h2 id="Early-Stop"><a href="#Early-Stop" class="headerlink" title="Early Stop"></a>Early Stop</h2><p>训练中，我们常常会将数据集分割训练集和验证集。Early Stop的提前终止思想是在验证集上的错误率到最小时停止训练（是的，一般来说验证集的错误率会先达到最小），而不要等到训练集的错误率到最小时（这时候验证集错误率已经变大了）再停止训练，不然过拟合几率更大</p>
<p>如图，左为训练集错误率，右为验证集错误率。虚线为Early Stop的点：</p>
<p><img src="/uploads/cnn_9.png" alt></p>
<h2 id="Data-Augmentation"><a href="#Data-Augmentation" class="headerlink" title="Data Augmentation"></a>Data Augmentation</h2><p>数据增强很好理解：有更多数据当然就能训练出更好的泛化模型。</p>
<p>但问题是，我们如何获取“有用”的数据。常用的方法是：</p>
<p>1）图像的扭曲，旋转等变换，加光照，改变颜色。<br>2）添加噪声<br>3）利用GAN生成</p>
<h2 id="Weight-Decay"><a href="#Weight-Decay" class="headerlink" title="Weight Decay"></a>Weight Decay</h2><p>权重衰减指的是在每次使用梯度下降进行权值更新过程中，对权值更新值的过大进行限制</p>
<p>也就是对<img src="https://latex.codecogs.com/gif.latex?a_{m&plus;1}=a_m-\eta&space;\Delta" title="a_{m+1}=a_m-\eta \Delta">中的<img src="https://latex.codecogs.com/gif.latex?a_m" title="a_m">乘以一个介于0到1之间的值，用来衰减权值，于是得到：</p>
<p><img src="https://latex.codecogs.com/gif.latex?a_{m&plus;1}=\gamma&space;a_m-\eta&space;\Delta" title="a_{m+1}=\gamma a_m-\eta \Delta"></p>
<p>这样的话防止权值过大。</p>
<p>权值过大，就是意味着当前训练出来的模型非常依赖某个或某些位置的元素，也就意味着训练过程中出现了明显的倾向。这是overfitting的表现。</p>
<p>上面是对于每次局部进行衰减，下面讲全局的正则化方法:</p>
<h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><p>对全局的损失函数加一个对权值过大的L2惩罚项，也就是各个权值的平方和：</p>
<p><img src="https://latex.codecogs.com/gif.latex?C=C_0&plus;\frac{\lambda&space;}{2n}\sum_{w}^{&space;}w^2" title="C=C_0+\frac{\lambda }{2n}\sum_{w}^{ }w^2"></p>
<p>当从这样一个损失函数推导出来的导数被用于梯度下降的参数更新，会是什么样的效果呢？</p>
<p>首先，求任意一个权值求偏导：</p>
<p><img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;w}=\frac{\partial&space;C_0}{\partial&space;w}&plus;\frac{\lambda&space;}{n}w" title="\frac{\partial C}{\partial w}=\frac{\partial C_0}{\partial w}+\frac{\lambda }{n}w"></p>
<p>其中<img src="https://latex.codecogs.com/gif.latex?\lambda" title="\lambda">为惩罚因子，<img src="https://latex.codecogs.com/gif.latex?n" title="n">为权值个数。</p>
<p>获得它的更新公式：</p>
<p><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;w_{m&plus;1}&=w_m-\eta&space;\Delta&space;\\&space;&=w_m-\eta&space;(\frac{\partial&space;C_0}{\partial&space;w_m}&plus;\frac{\lambda&space;}{n}w_m)&space;\\&space;&=(1-\frac{\eta&space;\lambda&space;}{n})w_m-\eta&space;\frac{\partial&space;C_0}{\partial&space;w_m}&space;\end{align*}"></p>
<p>其中<img src="https://latex.codecogs.com/gif.latex?1-\frac{\eta&space;\lambda&space;}{n}" title="1-\frac{\eta \lambda }{n}">小于1，实现了参数衰减，跟上面的参数衰减是一样的！</p>
<p>再来看偏置的偏导：</p>
<p><img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;b}=\frac{C_0}{b}&plus;0" title="\frac{\partial C}{\partial b}=\frac{C_0}{b}+0"></p>
<p>所以此正则对偏置没影响。</p>
<h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><p>与L2类似，只是惩罚项关于权值是一次的：</p>
<p><img src="https://latex.codecogs.com/gif.latex?C=C_0&plus;\frac{\lambda&space;}{n}\sum_{w}^{&space;}|w|"></p>
<p>首先，求任意一个权值求偏导：</p>
<p><img src="https://latex.codecogs.com/gif.latex?\frac{\partial&space;C}{\partial&space;w}=\frac{\partial&space;C_0}{\partial&space;w}&plus;\frac{\lambda&space;}{n}sgn(w)"></p>
<p>其中<img src="https://latex.codecogs.com/gif.latex?sgn(w)">表示取<img src="https://latex.codecogs.com/gif.latex?w">的符号，输出为1或-1</p>
<p>获得它的更新公式：</p>
<p><img src="https://latex.codecogs.com/gif.latex?\begin{align*}&space;w_{m&plus;1}&=w_m-\eta&space;\Delta&space;\\&space;&=w_m-\eta&space;(\frac{\partial&space;C_0}{\partial&space;w_m}&plus;\frac{\lambda&space;}{n}sgn(w_m))&space;\\&space;&=w_m-\frac{\eta&space;\lambda&space;}{n}sgn(w_m)-\eta&space;\frac{\partial&space;C_0}{\partial&space;w_m}&space;\end{align*}"></p>
<p>当<img src="https://latex.codecogs.com/gif.latex?w">为正时，更新后的<img src="https://latex.codecogs.com/gif.latex?w">变小。当<img src="https://latex.codecogs.com/gif.latex?w">为负时，更新后的<img src="https://latex.codecogs.com/gif.latex?w">变大。因此它的效果就是让w往0靠，实现了权值衰减。</p>
<h2 id="Learning-Rate-decay"><a href="#Learning-Rate-decay" class="headerlink" title="Learning Rate decay"></a>Learning Rate decay</h2><p>梯度下降训练在进行到后期，越来越接近最优值，权值更新的震荡越大，这个时候需要把学习率<img src="https://latex.codecogs.com/gif.latex?\eta" title="\eta">给衰减，以求更快更准确地抵达最优值：</p>
<p><img src="/uploads/cnn_10.png" alt></p>
<p>学习率的衰减一般采用的方式:</p>
<p>1) 线性衰减, 如：每5个epochs学习率减半<br>2) 指数衰减，如：每5个epochs将学习率乘以0.9，也就是衰减率为0.9</p>
<p>注：一个epochs就是把样本数据过了完整一般的意思</p>
<h1 id="各种CNN"><a href="#各种CNN" class="headerlink" title="各种CNN"></a>各种CNN</h1><p>CNN是关于卷积神经网络的统一概念，它的构造方式常常如下：</p>
<p>INPUT -&gt; [[CONV -&gt; RELU]*N -&gt; POOLING]*M -&gt; [FC -&gt; RELU]*K -&gt; FC</p>
<p>其中INPUT是输入，CONV表示卷积，POOLING表示池化，FC是全连接，N,M,K是循环数</p>
<p>到底哪种构造最好呢？答案是不知道。网络的构造没有公式，哪个有效哪个更好。于是在前人的实践中，产生了众多有效的优秀的CNN网络：</p>
<h2 id="LeNet-1986"><a href="#LeNet-1986" class="headerlink" title="LeNet (1986)"></a>LeNet (1986)</h2><p><img src="/uploads/cnn_11.png" alt></p>
<p>论文<a href="http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf" target="_blank" rel="noopener">在此</a></p>
<h2 id="AlexNet-2012"><a href="#AlexNet-2012" class="headerlink" title="AlexNet (2012)"></a>AlexNet (2012)</h2><p><img src="/uploads/cnn_12.png" alt></p>
<p>论文<a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf" target="_blank" rel="noopener">在此</a></p>
<h2 id="VGGNet-2014"><a href="#VGGNet-2014" class="headerlink" title="VGGNet (2014)"></a>VGGNet (2014)</h2><p><img src="/uploads/cnn_13.png" alt></p>
<p>论文<a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" rel="noopener">在此</a></p>
<h2 id="GoogleNet-2014"><a href="#GoogleNet-2014" class="headerlink" title="GoogleNet (2014)"></a>GoogleNet (2014)</h2><p><img src="/uploads/cnn_14.png" alt></p>
<p>论文<a href="https://www.cs.unc.edu/~wliu/papers/GoogLeNet.pdf" target="_blank" rel="noopener">在此</a></p>
<h2 id="ResNet-2015"><a href="#ResNet-2015" class="headerlink" title="ResNet (2015)"></a>ResNet (2015)</h2><p><img src="/uploads/cnn_15.png" alt></p>
<p>论文<a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="noopener">在此</a></p>
<p>以上。</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">

      
        <div class="post-tags">
         <br>
         <br>
<!--  Dorian Removed Start    
         
            <a href="/tags/Algorithm/" rel="tag"># Algorithm</a>
         
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
         
       Dorian Removed End -->
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/22/Neural_Network/" rel="next" title="Neural Network 神经网络">
                <i class="fa fa-chevron-left"></i> Neural Network 神经网络
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/01/Digit-Recognizer-By-CNN/" rel="prev" title="Digit Recognizer by CNN 基于卷积神经网络的手写数字识别">
                Digit Recognizer by CNN 基于卷积神经网络的手写数字识别 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="gitalk-container">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/eric_clapton.jpg" alt="Dorian Zi">
            
              <p class="site-author-name" itemprop="name">Dorian Zi</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">32</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">9</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/dorianzi" title="GitHub &rarr; https://github.com/dorianzi" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://kaggle.com/dorianzi" title="Kaggle &rarr; https://kaggle.com/dorianzi" rel="noopener" target="_blank"><i class="fa fa-fw fa-list-alt"></i>Kaggle</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://xiami.com/artist/mf8ydg642ef" title="Xiami &rarr; https://xiami.com/artist/mf8ydg642ef" rel="noopener" target="_blank"><i class="fa fa-fw fa-music"></i>Xiami</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://music.163.com/#/album?id=3080421" title="Netease &rarr; https://music.163.com/#/album?id=3080421" rel="noopener" target="_blank"><i class="fa fa-fw fa-headphones"></i>Netease</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://facebook.com/profile.php?id=100008679135728" title="FB Page &rarr; https://facebook.com/profile.php?id=100008679135728" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i>FB Page</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://instagram.com/dorian.zi/" title="Instagram &rarr; https://instagram.com/dorian.zi/" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://linkedin.com/in/dorian-zi-7620b6127/" title="Linkedin &rarr; https://linkedin.com/in/dorian-zi-7620b6127/" rel="noopener" target="_blank"><i class="fa fa-fw fa-linkedin"></i>Linkedin</a>
                </span>
              
            </div>
          

          <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=481876106&auto=1&height=66"></iframe>

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积和神经网络"><span class="nav-number">1.</span> <span class="nav-text">卷积和神经网络</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积"><span class="nav-number">1.1.</span> <span class="nav-text">卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积的神经网络表示"><span class="nav-number">1.2.</span> <span class="nav-text">卷积的神经网络表示</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#CNN的各层"><span class="nav-number">2.</span> <span class="nav-text">CNN的各层</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积层"><span class="nav-number">2.1.</span> <span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性整流层"><span class="nav-number">2.2.</span> <span class="nav-text">线性整流层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化层"><span class="nav-number">2.3.</span> <span class="nav-text">池化层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#全连接层"><span class="nav-number">2.4.</span> <span class="nav-text">全连接层</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网络优化"><span class="nav-number">3.</span> <span class="nav-text">网络优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Padding"><span class="nav-number">3.1.</span> <span class="nav-text">Padding</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参数共享"><span class="nav-number">3.2.</span> <span class="nav-text">参数共享</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#训练优化"><span class="nav-number">4.</span> <span class="nav-text">训练优化</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Dropout"><span class="nav-number">4.1.</span> <span class="nav-text">Dropout</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Early-Stop"><span class="nav-number">4.2.</span> <span class="nav-text">Early Stop</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Data-Augmentation"><span class="nav-number">4.3.</span> <span class="nav-text">Data Augmentation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Weight-Decay"><span class="nav-number">4.4.</span> <span class="nav-text">Weight Decay</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#L2正则化"><span class="nav-number">4.4.1.</span> <span class="nav-text">L2正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1正则化"><span class="nav-number">4.4.2.</span> <span class="nav-text">L1正则化</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Learning-Rate-decay"><span class="nav-number">4.5.</span> <span class="nav-text">Learning Rate decay</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#各种CNN"><span class="nav-number">5.</span> <span class="nav-text">各种CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#LeNet-1986"><span class="nav-number">5.1.</span> <span class="nav-text">LeNet (1986)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#AlexNet-2012"><span class="nav-number">5.2.</span> <span class="nav-text">AlexNet (2012)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGGNet-2014"><span class="nav-number">5.3.</span> <span class="nav-text">VGGNet (2014)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogleNet-2014"><span class="nav-number">5.4.</span> <span class="nav-text">GoogleNet (2014)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet-2015"><span class="nav-number">5.5.</span> <span class="nav-text">ResNet (2015)</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dorian Zi</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.1</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>




  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  


  
    

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '5b4b5d838e55b91b3713',
    clientSecret: 'ca4bfc7fee3940ef0896565d06b76890fd29ce40',
    repo: 'DorianZi.github.io',
    owner: 'DorianZi',
    admin: ['DorianZi'],
    id: md5(location.pathname),
    
      language: window.navigator.language || window.navigator.userLanguage,
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

  


  



  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=7.0.1"></script>



  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
