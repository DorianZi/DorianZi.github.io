<!DOCTYPE html>












  


<html class="theme-next gemini use-motion" lang>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
















  <meta name="baidu-site-verification" content="L6qAeUEWrk">











<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2">

<link rel="stylesheet" href="/css/main.css?v=7.0.1">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=7.0.1">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=7.0.1">


  <link rel="mask-icon" href="/images/logo.svg?v=7.0.1" color="#222">







<script id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '7.0.1',
    sidebar: {"position":"left","display":"always","offset":12,"onmobile":false,"dimmer":false},
    back2top: true,
    back2top_sidebar: false,
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '6O9OK26379',
      apiKey: 'd266e496228bce82728a87f4c2ea4800',
      indexName: 'MyHexo',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="本文将用TensorFlow来实现CNN经典的入门项目:手写数字识别 数据集 手写数字的数据集来自著名的MNIST(美国国家标准与技术研究所)，它包含了6万个训练样本和1万个测试样本，并且所有样本都已经标准化为28*28个像素，每个像素值在0~1之间。同时每张图片的储存方式已经扁平化为784（28*28）个元素的一维numpy序列。 网络结构 我们要构建的CNN网络大致如上，它实际上是使用了LeN">
<meta name="keywords" content="Algorithm,Deep Learning,Computer Vision,TensorFlow">
<meta property="og:type" content="article">
<meta property="og:title" content="Digit Recognizer by CNN 基于卷积神经网络的手写数字识别">
<meta property="og:url" content="https://dorianzi.github.io/2019/05/01/Digit-Recognizer-By-CNN/index.html">
<meta property="og:site_name" content="Dorian Scale">
<meta property="og:description" content="本文将用TensorFlow来实现CNN经典的入门项目:手写数字识别 数据集 手写数字的数据集来自著名的MNIST(美国国家标准与技术研究所)，它包含了6万个训练样本和1万个测试样本，并且所有样本都已经标准化为28*28个像素，每个像素值在0~1之间。同时每张图片的储存方式已经扁平化为784（28*28）个元素的一维numpy序列。 网络结构 我们要构建的CNN网络大致如上，它实际上是使用了LeN">
<meta property="og:locale" content="default">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_1.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_2.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_3.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_4.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_5.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_6.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_7.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_8.png">
<meta property="og:image" content="https://dorianzi.github.io/uploads/digit_recognizer_9.png">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?H(p,q)=-\sum_{i=1}^np(x_i)log(q(x_i))">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?p(x_i)">
<meta property="og:image" content="https://latex.codecogs.com/gif.latex?q(x_i)">
<meta property="og:updated_time" content="2019-06-01T03:27:04.277Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Digit Recognizer by CNN 基于卷积神经网络的手写数字识别">
<meta name="twitter:description" content="本文将用TensorFlow来实现CNN经典的入门项目:手写数字识别 数据集 手写数字的数据集来自著名的MNIST(美国国家标准与技术研究所)，它包含了6万个训练样本和1万个测试样本，并且所有样本都已经标准化为28*28个像素，每个像素值在0~1之间。同时每张图片的储存方式已经扁平化为784（28*28）个元素的一维numpy序列。 网络结构 我们要构建的CNN网络大致如上，它实际上是使用了LeN">
<meta name="twitter:image" content="https://dorianzi.github.io/uploads/digit_recognizer_1.png">






  <link rel="canonical" href="https://dorianzi.github.io/2019/05/01/Digit-Recognizer-By-CNN/">



<script id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>Digit Recognizer by CNN 基于卷积神经网络的手写数字识别 | Dorian Scale</title>
  






  <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?bdd9553b00b737f4e03ff3fc43e220f2";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>







  <noscript>
  <style>
  .use-motion .motion-element,
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-title { opacity: initial; }

  .use-motion .logo,
  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
    <a href="https://github.com/DorianZi/DorianZi.github.io/tree/master" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewbox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"/><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"/><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"/></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Dorian Scale</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="Toggle navigation bar">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">

    
    
    
      
    

    

    <a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i> <br>Home</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">

    
    
    
      
    

    

    <a href="/categories/" rel="section"><i class="menu-item-icon fa fa-fw fa-th"></i> <br>Categories</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">

    
    
    
      
    

    

    <a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i> <br>Tags</a>

  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">

    
    
    
      
    

    

    <a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i> <br>Archives</a>

  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>Search</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://dorianzi.github.io/2019/05/01/Digit-Recognizer-By-CNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Dorian Zi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/uploads/eric_clapton.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Dorian Scale">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Digit Recognizer by CNN 基于卷积神经网络的手写数字识别

              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              

              
                
              

              <time title="Created: 2019-05-01 08:17:19" itemprop="dateCreated datePublished" datetime="2019-05-01T08:17:19+08:00">2019-05-01</time>
            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Technic/" itemprop="url" rel="index"><span itemprop="name">Technic</span></a></span>

                
                
              
            </span>
          

          
            
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
             Views:  
            <span class="busuanzi-value" id="busuanzi_value_page_pv"></span>
            </span>
          

          

          
          
          <!--Dorian Added Start-->
          
            <div class="post-tags">
              
                <a href="/tags/Algorithm/" <i class="fa fa-tag"> Algorithm</a>
              
                <a href="/tags/Deep-Learning/" <i class="fa fa-tag"> Deep Learning</a>
              
                <a href="/tags/Computer-Vision/" <i class="fa fa-tag"> Computer Vision</a>
              
                <a href="/tags/TensorFlow/" <i class="fa fa-tag"> TensorFlow</a>
              
            </div>
          
          <!--Dorian Added End-->
        
        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>本文将用TensorFlow来实现CNN经典的入门项目:手写数字识别</p>
<h1 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h1><p><img src="/uploads/digit_recognizer_1.png" alt></p>
<p>手写数字的数据集来自著名的MNIST(美国国家标准与技术研究所)，它包含了6万个训练样本和1万个测试样本，并且所有样本都已经标准化为28*28个像素，每个像素值在0~1之间。同时每张图片的储存方式已经扁平化为784（28*28）个元素的一维numpy序列。</p>
<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p><img src="/uploads/digit_recognizer_2.png" alt></p>
<p>我们要构建的CNN网络大致如上，它实际上是使用了<a href="https://dorianzi.github.io/2019/04/25/CNN/#LeNet-1986">LeNet</a>:</p>
<p><img src="/uploads/digit_recognizer_3.png" alt></p>
<h1 id="代码解析"><a href="#代码解析" class="headerlink" title="代码解析"></a>代码解析</h1><p>完整代码<a href="https://github.com/DorianZi/kaggle/blob/master/digit_recognizer/digit_recognizer.py" target="_blank" rel="noopener">见此</a></p>
<h2 id="安装TensorFlow"><a href="#安装TensorFlow" class="headerlink" title="安装TensorFlow"></a>安装TensorFlow</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">$ sudo pip install tensorflow</span><br><span class="line">如果用到CUDA则为：</span><br><span class="line">$ sudo pip install tensorflow-gpu</span><br><span class="line"></span><br><span class="line">以上命令会按照时候本机的最新版本。如果要安装指定版本（可能不兼容），使用：</span><br><span class="line">$ sudo pip install tensorflow-gpu==1.70</span><br><span class="line"></span><br><span class="line">查看安装的版本：</span><br><span class="line">$ pip freeze</span><br></pre></td></tr></table></figure>
<h2 id="获得数据集"><a href="#获得数据集" class="headerlink" title="获得数据集"></a>获得数据集</h2><p>开始我们的coding.</p>
<h3 id="从TensorFlow获取"><a href="#从TensorFlow获取" class="headerlink" title="从TensorFlow获取"></a>从TensorFlow获取</h3><p>首先，获取数据集，可以通过tensorflow官方api直接拿到mnist数据集</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 导入mnist数据集</span><br><span class="line">from tensorflow.examples.tutorials.mnist import input_data</span><br><span class="line"></span><br><span class="line"># 数据压缩包下载保存到/tmp/data下</span><br><span class="line">mnist = input_data.read_data_sets(&quot;/tmp/data/&quot;, one_hot=False)</span><br><span class="line"></span><br><span class="line"># 分别在得到train和test数据集，images的类型为numpy.ndarray</span><br><span class="line">print(mnist.train.images)</span><br><span class="line">print(mnist.test.images)</span><br></pre></td></tr></table></figure>
<h3 id="从Kaggle比赛项目获取"><a href="#从Kaggle比赛项目获取" class="headerlink" title="从Kaggle比赛项目获取"></a>从Kaggle比赛项目获取</h3><p>本文中的完整代码是Kaggle比赛的项目，数据集在该<a href="https://www.kaggle.com/c/digit-recognizer/data" target="_blank" rel="noopener">比赛项目页面</a>可以本地下载获得。下载得到的训练集为train.csv，测试集为test.csv</p>
<p>train.csv的格式如下，test.csv相比train.csv少了label列</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">label    pixel0    pixel1    pixel2    pixel3    ...   pixel783</span><br><span class="line">1          0         255       0         0       ...      0</span><br><span class="line">4          0         0         0         0       ...      0</span><br><span class="line">0          0         0         98        0       ...      0</span><br><span class="line">...</span><br><span class="line">7          0         0         0         0       ...      0</span><br></pre></td></tr></table></figure>
<p>以上格式的csv可以通过pandas模块的read_csv读取：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line"># 读取csv文件为DataFrame</span><br><span class="line">csvDF = pd.read_csv(&quot;train.csv&quot;)</span><br><span class="line"></span><br><span class="line"># 将DataFrame中的&apos;label&apos;列去掉</span><br><span class="line">train_data = csvDF.drop(columns = [&apos;label&apos;])</span><br><span class="line"></span><br><span class="line"># 去掉表头，拿到纯数据，也就是格式为numpy.ndarray的数据</span><br><span class="line">train_data = train_data.values</span><br><span class="line"></span><br><span class="line"># 将原shape为(42000,784)的数据变换为(42000,28,28,1)的数据，并且将每个数据由原来的numpy.int64类型变成numpy.float32类型</span><br><span class="line">train_data = train_data.reshape(-1,28,28,1).astype(&apos;float32&apos;)</span><br><span class="line"></span><br><span class="line"># 获取&apos;label&apos;列数据，此时为Series类型</span><br><span class="line">train_labels = csvDF[&apos;label&apos;]</span><br><span class="line"></span><br><span class="line"># 获取纯数据，numpy.ndarray类型</span><br><span class="line">train_labels = train_labels.values</span><br><span class="line"></span><br><span class="line"># 引入sklearn模块</span><br><span class="line">from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder</span><br><span class="line"></span><br><span class="line"># 进行标签编码， 这里和train_labels = train_labels.reshape(-1,1)是一样的</span><br><span class="line">train_labels = LabelEncoder().fit_transform(train_labels)[:, None]</span><br><span class="line"></span><br><span class="line"># 进行独热编码</span><br><span class="line">train_labels = OneHotEncoder().fit_transform(train_labels).todense()</span><br><span class="line"></span><br><span class="line"># 读取test的csv文件</span><br><span class="line">csvDF = pd.read_csv(&quot;test.csv&quot;)</span><br><span class="line"></span><br><span class="line"># 数据储存到shape是(28000,28,28,1)，每个数据类型为numpy.float32的numpy.ndarray变量中</span><br><span class="line">test_data = csvDF.values.reshape(-1,28,28,1).astype(&apos;float32&apos;)</span><br></pre></td></tr></table></figure>
<h3 id="代码解析-1"><a href="#代码解析-1" class="headerlink" title="代码解析"></a>代码解析</h3><h4 id="pandas中的数据结构"><a href="#pandas中的数据结构" class="headerlink" title="pandas中的数据结构"></a>pandas中的数据结构</h4><p>上面提到的DataFrame是pandas定义的一种格式，是一个类，这里csvDF是它的一个实例。在pandas常用的数据格式是三种：它自己的DataFrame,Series和numpy的ndarray。他们之间的关系可以描述如下：</p>
<p>DataFrame可以通过字典方式访问每一列，如csvDF[‘label’]或csvDF.label代表’label’所在的列，csvDF[‘label’]或csvDF.label就是Series格式的</p>
<p>对于DataFrame来说，直接取数值（即去掉表头）: csvDF.values就得到了二维的numpy.ndarray格式数据；同理对于Series来说也可以去掉标注信息：csvDF[‘label’].values 获得一维度的numpy.ndarray格式数据。</p>
<h4 id="多维数据在numpy-ndarray中的表示"><a href="#多维数据在numpy-ndarray中的表示" class="headerlink" title="多维数据在numpy.ndarray中的表示"></a>多维数据在numpy.ndarray中的表示</h4><p>numpy.ndarray中的多维数据是通过列表嵌套得到的。</p>
<p>表示一个shape为(9,)的数据：[1,2,3,4,5,6,7,8,9]<br>reshape为(3,3)的数据：[[1,2,3], [4,5,6], [7,8,9]]<br>reshape为(3,3,1)的数据：[[[1],[2],[3]], [[4],[5],[6]], [[7],[8],[9]]]</p>
<h4 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h4><p>（蓝色，红色，黄色）可以标签编码为(1,2,3)，但是这样在计算上会造成 “(蓝色+黄色)/2=红色” 的不良后果。通过独热编码将它们映射到欧式空间可以解决这个问题：</p>
<p>蓝色=(1,0,0)<br>红色=(0,1,0)<br>黄色=(0,0,1)</p>
<p>在本文中，我们的label已经是0~9的数字，可以作为标签编码使用。但是考虑到神经网络最后有10个输出，为独热编码形式，所以这里我们使用独热编码来表示。</p>
<h3 id="验证集分割"><a href="#验证集分割" class="headerlink" title="验证集分割"></a>验证集分割</h3><p>将训练集分割为实际训练集和验证集，为常用的训练前数据的准备方法。我们的训练过程通过考察该验证集的预测准确率来决定是否停止，而不是考察实际训练集的准确率。这样可以有效地减少过拟合可能。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"># 拿出1000个数据作为验证集</span><br><span class="line">VALID = 1000</span><br><span class="line"></span><br><span class="line"># 抽取出前1000个数据出来作为验证集</span><br><span class="line">valid_data = train_data[0:VALID]</span><br><span class="line"></span><br><span class="line"># 删掉验证集，剩下的就是实际训练集</span><br><span class="line">train_data = np.delete(train_data,np.s_[0:VALID],0)</span><br></pre></td></tr></table></figure>
<p>上面代码中np.delete接受的三个参数分别为：numpy.ndarray类型的待切割数据集，list类型的被删除的行（列）的列表，指定删除行（0）或列（1）</p>
<p>而上面使用的np.s_[0:1000]有特殊的功能，它是指取得指定范围的标号列表，也就是[0,1,2,3,…,999]</p>
<h2 id="使用TensorFlow构建CNN网络"><a href="#使用TensorFlow构建CNN网络" class="headerlink" title="使用TensorFlow构建CNN网络"></a>使用TensorFlow构建CNN网络</h2><p>TensorFlow构建网络的方式大体上分两个步骤：1）先通过创建占位符号，构建图 2）然后在运行图的时候将数据喂进去，实现训练和预测。<br>构建图的过程是设计网络的过程，这中间用到的数据变量，都是“空壳”，它们占用了内存，但是里面并没有数据。运行的图的时候一定要喂数据，否则空图是不能运行处结果的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br></pre></td><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line"></span><br><span class="line"># 定义输入数据的占位符，shape为（None,28,28,1）,其中None表示可以是任何数，数据类型为tf.float32，其实和np.float32没区别</span><br><span class="line"># 被定义的x变量在之后会被喂进上面的训练数据，而None之所以不设为1，是为了批量训练（一次性喂多行数据）准备的</span><br><span class="line">x = tf.placeholder(tf.float32, [None,28,28,1])</span><br><span class="line"></span><br><span class="line"># 输入label的占位符，且该label已经是独热编码形式，在训练的时候会被喂入train_labels的每一行数据</span><br><span class="line">y = tf.placeholder(tf.float32,[None,10])</span><br><span class="line"></span><br><span class="line"># 定义5*5的卷积核，其数值为随机数，shape为(5,5,1,32)</span><br><span class="line">w1 = tf.Variable(tf.random_normal([5,5,1,32]))</span><br><span class="line"></span><br><span class="line"># 定义偏置，随机初始化</span><br><span class="line">b1 = tf.Variable(tf.random_normal([32]))</span><br><span class="line"></span><br><span class="line"># 第二次卷积的卷积核</span><br><span class="line">w2 = tf.Variable(tf.random_normal([5,5,32,64]))</span><br><span class="line"></span><br><span class="line"># 第二次卷积的偏置</span><br><span class="line">b2 = tf.Variable(tf.random_normal([64]))</span><br><span class="line"></span><br><span class="line"># 第三次卷积的卷积核</span><br><span class="line">w3 = tf.Variable(tf.random_normal([5,5,64,64]))</span><br><span class="line"></span><br><span class="line"># 第三次卷积的偏置</span><br><span class="line">b3 = tf.Variable(tf.random_normal([64]))</span><br><span class="line"></span><br><span class="line"># 第一次全连接的权重</span><br><span class="line">wf_1 = tf.Variable(tf.random_normal([4*4*64,1024]))</span><br><span class="line"></span><br><span class="line"># 第一次全连接的偏置</span><br><span class="line">bf_1 = tf.Variable(tf.random_normal([1024]))</span><br><span class="line"></span><br><span class="line"># dropout里的保留率</span><br><span class="line">keep_prob = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"># 第二次全连接的权重</span><br><span class="line">wf_2 = tf.Variable(tf.random_normal([1024,10]))</span><br><span class="line"></span><br><span class="line"># 第二次全连接的偏置</span><br><span class="line">bf_2 = tf.Variable(tf.random_normal([10]))</span><br><span class="line"></span><br><span class="line"># 梯度下降算法的学习率</span><br><span class="line">learn_rate = tf.placeholder(tf.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def conv2d(X,W,b,k=2):</span><br><span class="line">    # 二维卷积</span><br><span class="line">    conv = tf.nn.conv2d(X,W,strides=[1,1,1,1], padding=&apos;SAME&apos;)</span><br><span class="line">    # 加偏置。将b中第i个元素加到conv中第i个通道里所有元素上</span><br><span class="line">    conv = tf.nn.bias_add(conv,b)</span><br><span class="line">    # 通过relu激活每一个元素（即保留正数），并且不改变conv的shape</span><br><span class="line">    conv = tf.nn.relu(conv)</span><br><span class="line">    # 最大池化</span><br><span class="line">    conv = tf.nn.max_pool(conv, ksize=[1, k, k, 1], strides=[1, k, k, 1], padding=&apos;SAME&apos;)</span><br><span class="line">    return conv</span><br><span class="line"></span><br><span class="line"># 连续三次conv -&gt; bias -&gt; relue -&gt; pooling 操作</span><br><span class="line">co1 = conv2d(x, w1, b1, k=2)                 # co1的shape为(?,14,14,32)</span><br><span class="line">co2 = conv2d(co1, w2, b2, k=2)               # co2的shape为(?,7,7,64)</span><br><span class="line">co3 = conv2d(co2, w3, b3, k=2)               # co3的shape为(?,4,4,64)，因为池化时有补零，所以7-&gt;4</span><br><span class="line"></span><br><span class="line"># 扁平化为（?,4*4*64)，为全连接作准备</span><br><span class="line">co3 = tf.reshape(co3,[-1,4*4*64])            # 这里用-1而不用None，是因为这里不是初始化，这里的cos3已经被分配空间了</span><br><span class="line"></span><br><span class="line"># 第一次全连接并用relu激活。tf.matmul为矩阵乘法，这里计算的是shape变化为（?,4*4*64) *（4*4*64,1024) = (?,1024)</span><br><span class="line">fc = tf.nn.relu(tf.matmul(co3,wf_1) + bf_1)  # fc的shape为(?,1024)</span><br><span class="line"></span><br><span class="line"># 以keep_prob的保留概率进行dropout，防止过拟合</span><br><span class="line">fc_keep = tf.nn.dropout(fc, keep_prob)</span><br><span class="line"></span><br><span class="line"># 第二次全连接，以获得每个数据的10位编码，为softmax进行归一概率化做准备</span><br><span class="line">logits  = tf.matmul(fc_keep, wf_2) + bf_2    # logits的shape为(?,10) = (?,1024) * (1024,10)</span><br><span class="line"></span><br><span class="line"># 使用softmax进行独热分类预测，输出值shape为(?,10)，它的每一个元素代表预测出来的对应类别的概率</span><br><span class="line">prediction = tf.nn.softmax(logits)</span><br><span class="line"></span><br><span class="line"># 计算对shape为(?,10)计算每一行的交叉熵得到shape为（?,1）的数据，然后计算每个元素的均值得到单一数值loss</span><br><span class="line">loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=y))</span><br><span class="line"></span><br><span class="line"># 使用随机梯度下降的优化算法Adam对loss进行优化</span><br><span class="line">optimizer = tf.train.AdamOptimizer(learn_rate).minimize(loss)</span><br><span class="line"></span><br><span class="line"># tf.argmax(a,axis=1)按行获得最大值的下标号,输出shape为(?,1)，这么做是因为最大值的那个类别才是被认为预测的分类</span><br><span class="line"># tf.equal(A,B)按元素获取bool值，输出shape为A.shape以及B.shape。此例中为(?,1)</span><br><span class="line">correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))</span><br><span class="line"></span><br><span class="line"># 用tf.cast将每个位置的数值转换为tf.float32类型，然后再求均值。</span><br><span class="line"># 这里的均值之所以可以表示准确度是因为correct_pred的每一位是非0即1的值，求准确度就是求1出现的频率，也恰好是求均值</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))</span><br></pre></td></tr></table></figure>
<h3 id="代码讲解"><a href="#代码讲解" class="headerlink" title="代码讲解"></a>代码讲解</h3><h4 id="tf-nn-conv2d函数"><a href="#tf-nn-conv2d函数" class="headerlink" title="tf.nn.conv2d函数"></a>tf.nn.conv2d函数</h4><p>conv2函数里的参数strides表示卷积核的扫描步长，两边两个一般默认为1(因为不用对batch和channel方向做大于1的步长扫描)，中间两个代表纵向和横向扫描的步长。如strides=[1,4,5,1]表示卷积核纵向一次移动4个元素，横向一次移动5个元素。</p>
<p>conv2函数里的参数padding=’SAME’代表通过补零方式，保证卷积输出的数据和原数据shape保持一致，否则padding=’VALID’表示不补零，数据输出将有shape损失。它的效果在之前的文章中有过<a href="https://dorianzi.github.io/2019/04/25/CNN/#Padding">介绍</a></p>
<p>当被卷积数据和卷积核的shape分别为（None,28,28,1），(5,5,1,32)，它们是怎么被conv2d函数完成卷积的呢？</p>
<p>在conv2d函数看来，（None,28,28,1）中第一个维度None被认为是batch数，喂数据的时候喂入多行数据的时候就是多个卷积操作平行进行，互不干涉。第二、三个维度被认为是二维数据的高和宽，也就是数据为28*28形状。第四个维度被认为是数据的通道数，比如一张shape为(2,2,3)的彩色图片数据为[[[123,111,88], [123,234,87]], [[88,65,29], [76,20,246]]]，它是2*2大小，而每个元素又分成三部分，每部分是RGB的一个值。</p>
<p>(5,5,1,32)前两个维度被认为是每个卷积核的形状，第三个维度的值1是输入通道数，对应的是被卷积数据的通道数，而第四个维度的值32是卷积后输出的通道数。</p>
<p>综合描述（None,28,28,1）和(5,5,1,32)的conv2d操作，就是对多行28*28的1通道的图片，使用1*32个5*5的卷积核进行卷积。</p>
<p>图解卷积发生的方式：</p>
<p><img src="/uploads/digit_recognizer_4.png" alt></p>
<p>这里要着重理解一下卷积的分配方式和求和方式。思考一个问题：当我们把4个通道的图片进行conv2d操作之后变成了3个通道，这个过程中怎么对这4个通道都“公平”，并且求出来的3个通道也是公平的？</p>
<p>CNN的设计中实现了公平：对每个通道用不同的卷积核进行卷积，然后求和，这样形成一个新的通道。以上过程进行3次，得到3个通道。</p>
<p>之所以说对4个通道是公平的，是因为所有4个通道都被卷积，且没有一个通道被使用了特殊的卷积核，大家都是用随机的不同的卷积核，卷积完了进行求和，没有哪个的权重更大。</p>
<p>之所以说对生成的3个通道是公平的，是因为以上过程进行的3次重复，没有哪次的权重是更多的。</p>
<p>如果你能创造新的“公平”方式且能使得CNN的预测结果得到提升，那么恭喜你，你创造了一种CNN的改进算法。</p>
<h4 id="tf-nn-bias-add函数"><a href="#tf-nn-bias-add函数" class="headerlink" title="tf.nn.bias_add函数"></a>tf.nn.bias_add函数</h4><p>它是tf.nn.add的一种特例。tf.nn.add(x,y)的第二个参数y可以是单数值，这样话，该数值可以广播并相加到矩阵的任何一个元素上。<br>tf.nn.bias_add(x,y)的第二个参数y的维度必须跟x的最后一个维度是一致的</p>
<h4 id="tf-nn-max-pool函数"><a href="#tf-nn-max-pool函数" class="headerlink" title="tf.nn.max_pool函数"></a>tf.nn.max_pool函数</h4><p>进行最大池化的函数tf.nn.max_pool(value, ksize, strides, padding, name=None)</p>
<p>value为被池化对象；ksize=[1,height,width,1]表示池化窗口，因为不想在batch和channels上做池化，所以这两个维度设为了1；strides跟卷积一样，是每个维度上的步长；padding跟卷积一样，表示是否补零</p>
<p>比如shape为（1,4,4,2）的图片数据A，为：<br><img src="/uploads/digit_recognizer_5.png" alt><br><img src="/uploads/digit_recognizer_6.png" alt></p>
<p>经过池化操作tf.nn.max_pool(A,[1,2,2,1],[1,1,1,1],padding=’VALID’)之后得到shape为（1,3,3,2）的图片数据：<br><img src="/uploads/digit_recognizer_7.png" alt><br><img src="/uploads/digit_recognizer_8.png" alt></p>
<h4 id="tf-nn-softmax函数"><a href="#tf-nn-softmax函数" class="headerlink" title="tf.nn.softmax函数"></a>tf.nn.softmax函数</h4><p>softmax对矩阵的每一行进行如下归一化操作，使得每一位都是相对于该行的概率(大小在0~1之间)：<br><img src="/uploads/digit_recognizer_9.png" alt></p>
<h4 id="tf-nn-softmax-cross-entropy-with-logits-v2函数"><a href="#tf-nn-softmax-cross-entropy-with-logits-v2函数" class="headerlink" title="tf.nn.softmax_cross_entropy_with_logits_v2函数"></a>tf.nn.softmax_cross_entropy_with_logits_v2函数</h4><p>tf.nn.softmax_cross_entropy_with_logits(logits, labels, name=None)用来计算交叉熵。</p>
<p>第一个参数logits是预测的分布，第二个参数label是真实的分布，他们的shape为（batchsize，num_classes），输出的shape为（batchsize，1）</p>
<p>交叉熵的公式是：</p>
<p><img src="https://latex.codecogs.com/gif.latex?H(p,q)=-\sum_{i=1}^np(x_i)log(q(x_i))"></p>
<p>其中<img src="https://latex.codecogs.com/gif.latex?p(x_i)">为真实的概率分布，<img src="https://latex.codecogs.com/gif.latex?q(x_i)">为预测的概率分布。</p>
<p>预测的概率分布越接近真实概率分布，则交叉熵越小。</p>
<h2 id="训练和预测"><a href="#训练和预测" class="headerlink" title="训练和预测"></a>训练和预测</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br></pre></td><td class="code"><pre><span class="line"># 创建TensorFlow的会话，相当于初始化。</span><br><span class="line">sess = tf.Session()</span><br><span class="line"></span><br><span class="line"># 构建关于所有全局变量初始化的计算图，这样就不需要一个一个地去初始化之前定义的变量</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line"></span><br><span class="line"># 运行init计算图，将所有定义的变量初始化</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"># 将训练数据和label进行乱序，然后生成队列，每次可以从队列出队1000个数据</span><br><span class="line"># 这里定义的还是队列图，需要用tf.train.start_queue_runners使得队列图运转起来</span><br><span class="line">data_queue, labels_queue = tf.train.shuffle_batch([train_data,train_labels],</span><br><span class="line">                                                   batch_size=1000,</span><br><span class="line">                                                   capacity=50000,</span><br><span class="line">                                                   min_after_dequeue=10000,</span><br><span class="line">                                                   enqueue_many=True)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"># 创建协调器用来协调线程</span><br><span class="line">coord = tf.train.Coordinator()</span><br><span class="line"></span><br><span class="line"># start_queue_runners会启动多线程，需要用coord对线程进行协调，当然最基础的还是需要指定sess，tf所有操作都必须在session中</span><br><span class="line"># 启动多线程的原因是tf运行过程中，数据（并非针对上面的shuffle_batch）的读取和计算需要同时进行，而不是计算的时候，取数据就停滞</span><br><span class="line">threads = tf.train.start_queue_runners(sess,coord)</span><br><span class="line"></span><br><span class="line"># 每个epoch的迭代次数</span><br><span class="line">steps_per_epoch = int(train_data.shape[0]/train_batch_size)</span><br><span class="line"></span><br><span class="line"># 训练200轮，每一轮意味着过完一遍训练数据</span><br><span class="line">epochs = 200</span><br><span class="line"></span><br><span class="line"># 总迭代数</span><br><span class="line">steps = steps_per_epoch * epochs</span><br><span class="line"></span><br><span class="line">print (&quot;All steps:  &#123;0&#125;*&#123;1&#125; = &#123;2&#125;&quot;.format(steps_per_epoch,epochs,steps))</span><br><span class="line"></span><br><span class="line"># early stop标志位</span><br><span class="line">earlyStopProc = False</span><br><span class="line"></span><br><span class="line"># 辅助early stop标志位</span><br><span class="line">noImproveCount = 0</span><br><span class="line"></span><br><span class="line"># 当前epoch</span><br><span class="line">cur_epoch = 1</span><br><span class="line"></span><br><span class="line"># 初始梯度下降的学习率</span><br><span class="line">initial_learn_rate = 0.001</span><br><span class="line"></span><br><span class="line"># 当前学习率</span><br><span class="line">cur_learn_rate = 0.001</span><br><span class="line"></span><br><span class="line">for step in range(1,steps+1):</span><br><span class="line">    # 获取本轮的batch数据</span><br><span class="line">    batch_x, batch_y = sess.run([data_queue, labels_queue])</span><br><span class="line">    </span><br><span class="line">    # 将数据喂入优化器进行梯度下降优化，结果是更新了optimizer图中的权重，偏置</span><br><span class="line">    sess.run(optimizer,feed_dict=&#123;x:batch_x,</span><br><span class="line">                                  y:batch_y,</span><br><span class="line">                                  learn_rate: cur_learn_rate,</span><br><span class="line">                                  keep_prob: 0.75&#125;)</span><br><span class="line">    </span><br><span class="line">    # 每100次进行状态检查</span><br><span class="line">    if step % 100 == 0 or step == 1:</span><br><span class="line"></span><br><span class="line">        # 使用上次sess.run已更新的权重和偏置，再次喂入本轮batch以计算损失和训练数据准确率。计算过程使用100%的数据，不dropout</span><br><span class="line">        lossval, accval = sess.run([loss, accuracy], feed_dict=&#123;x: batch_x,</span><br><span class="line">                                                                y: batch_y,</span><br><span class="line">                                                                keep_prob: 1.0&#125;)   # 计算过程使用100%的数据，不dropout</span><br><span class="line"></span><br><span class="line">        # 喂入验证数据，计算验证集准确率，计算过程使用100%的数据，不dropout</span><br><span class="line">        validacc = sess.run(accuracy, feed_dict=&#123;x: valid_data,</span><br><span class="line">                                                 y: valid_labels,</span><br><span class="line">                                                 keep_prob: 1.0&#125;)</span><br><span class="line"></span><br><span class="line">        print (&quot;Epoch &#123;0&#125;/&#123;1&#125;, Step &#123;2&#125;/&#123;3&#125;: Learn Rate=&#123;4&#125;, Minibatch Loss=&#123;5&#125;, Training Accuracy=&#123;6&#125;, Validation Accuracy=&#123;7&#125;&quot;.format(cur_epoch,epochs,step,steps,cur_learn_rate,lossval,accval,validacc))</span><br><span class="line"></span><br><span class="line">        # //表示整数除法，保留整数位</span><br><span class="line">        cur_epoch = step//steps_per_epoch + 1</span><br><span class="line">        if cur_epoch &gt; 1:</span><br><span class="line">            # 每过10个epoch，就将学习率衰减到当前学习率的0.9</span><br><span class="line">            cur_learn_rate = initial_learn_rate * pow(0.9,(cur_epoch-1)//10)</span><br><span class="line"></span><br><span class="line">        # 在训练大于100个epoch的前提下当验证集准确率大于0.993则立即停止训练</span><br><span class="line">        # 若没大于0.993但近500次的验证集准确率都没有提升，则也停止训练</span><br><span class="line">        if earlyStopProc:</span><br><span class="line">            if validacc &gt; 0.993:</span><br><span class="line">                print(&quot;validacc &gt; 0.993 in latest 500. Early Stopping !&quot;)</span><br><span class="line">                break</span><br><span class="line">            noImproveCount += 1</span><br><span class="line">            if noImproveCount &gt; 5:</span><br><span class="line">                noImproveCount = 0</span><br><span class="line">                earlyStopProc = False</span><br><span class="line">        if validacc &gt; 0.993 and cur_epoch &gt; 100:</span><br><span class="line">            earlyStopProc = True</span><br><span class="line"></span><br><span class="line">        # 训练大于20个epoch，验证集的准确率还是低于0.9，则本次训练不正常（可能参数初始化导致梯度消失），终止训练</span><br><span class="line">        if cur_epoch &gt; 20 and validacc &lt; 0.9:</span><br><span class="line">            print(&quot;Broken. Stop!&quot;)</span><br><span class="line">            break</span><br><span class="line">        print (&quot;Trainning Finished!&quot;)</span><br><span class="line"></span><br><span class="line">        # 对所有线程发送终止请求</span><br><span class="line">        coord.request_stop()</span><br><span class="line">        coord.join(threads)</span><br><span class="line"></span><br><span class="line"># 对测试机数据进行分类预测。通过tf.argmax将独热编码prediction（它的shape为(?,10)）每一行的下标号取出，即为分类数字</span><br><span class="line"># 预测的时候喂入测试数据集，并且不使用dropout，返回的pred_number的shape为(?,1)</span><br><span class="line">pred_number = sess.run(tf.argmax(prediction,1),</span><br><span class="line">                       feed_dict=&#123;x:test_data, keep_prob: 1.0&#125;)</span><br><span class="line"># 关闭会话</span><br><span class="line">sess.close()</span><br></pre></td></tr></table></figure>
<h3 id="代码讲解-1"><a href="#代码讲解-1" class="headerlink" title="代码讲解"></a>代码讲解</h3><h4 id="sess-run函数"><a href="#sess-run函数" class="headerlink" title="sess.run函数"></a>sess.run函数</h4><p>sess.run(arg0, feed_dict=dict)第一个参数arg0为构建好的图或者多个图的列表，我们要run的就是这个arg0，run出结果之后函数返回也是这个arg0的计算值，feed_dict指定在运行过程喂数据的路径</p>
<h4 id="tf-train-shuffle-batch函数"><a href="#tf-train-shuffle-batch函数" class="headerlink" title="tf.train.shuffle_batch函数"></a>tf.train.shuffle_batch函数</h4><p>tf.train.shuffle_batch([train_data,train_labels],batch_size=1000, capacity=50000,min_after_dequeue=10000, enqueue_many=True) 工作方式为：</p>
<p>从420000条总数据里面，取出50000条数据组成一个小队列，并且打乱顺序，从队尾取出1000条数据，然后从总数据里面拿1000条过来补充到队头，再次打乱顺序，然后继续从队尾取出1000条，然后再打乱，再补充……当补充进来的数据超过了总数据，就再回到总数据的开始继续拿数据补充。</p>
<p>min_after_dequeue起的作用是要求capacity被取走batch_size的数据之后，队列里剩下的数据量要不小于min_after_dequeue</p>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>在<strong>训练之前</strong>，我们可以通过Data augmentation获得更多的数据。数据更多当然就更有利于训练出精度更高，泛化能力更强的模型。</p>
<p>见代码：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"># 使用keras里的ImageDataGenerator函数进行图片增广</span><br><span class="line">from keras.preprocessing.image import ImageDataGenerator</span><br><span class="line"></span><br><span class="line"># 导入绘图工具</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line">import matplotlib.cm as cm</span><br><span class="line"></span><br><span class="line">def augTrainData(train_data, aug_times=1):</span><br><span class="line">    print (&quot;Before augmentaion: &#123;0&#125;, &#123;1&#125;&quot;.format(train_data.shape,train_labels.shape))</span><br><span class="line">    datagen = ImageDataGenerator(rotation_range=10,         # 随机旋转10度</span><br><span class="line">                                 zoom_range = 0.1,          # 随机缩放范围是±0.1</span><br><span class="line">                                 width_shift_range=0.1,     # 随机水平移动范围是±0.1</span><br><span class="line">                                 height_shift_range=0.1)    # 随机上下移动范围是±0.1</span><br><span class="line"></span><br><span class="line">    # 载入数据，生成迭代器，一次输出len(train_data)张图片,通过next()进行迭代</span><br><span class="line">    imgs_flow = datagen.flow(train_data.copy(), batch_size=len(train_data), shuffle = False)</span><br><span class="line"></span><br><span class="line">    # label直接复制，无需进行变换</span><br><span class="line">    labels_aug = train_labels.copy()</span><br><span class="line"></span><br><span class="line">    # 将数据扩展aug_times倍</span><br><span class="line">    for i in range(aug_times):</span><br><span class="line">        # 取出len(train_data)张图片</span><br><span class="line">        imgs_aug = imgs_flow.next()</span><br><span class="line">        # 增加行</span><br><span class="line">        train_data = np.append(train_data,imgs_aug,0)</span><br><span class="line">        train_labels = np.append(train_labels,labels_aug,0)</span><br><span class="line">    print (&quot;After augmentaion: &#123;0&#125;, &#123;1&#125;&quot;.format(train_data.shape,train_labels.shape))</span><br><span class="line">    try:</span><br><span class="line">        print (&quot;Trying to show augmentation effects&quot;)</span><br><span class="line"></span><br><span class="line">        # 用subplots绘制多个子图</span><br><span class="line">        # fig为整个图的对象，axs为多个（5*10）子图对象的二维列表，每个子图的高为15pixel，宽为9pixel</span><br><span class="line">        fig,axs = plt.subplots(5,10, figsize=(15,9))</span><br><span class="line">        </span><br><span class="line">        # 对不同位置子图绘制图片</span><br><span class="line">        axs[0,1].imshow(train_data[len(train_data)//1000*1].reshape(28,28), cmap=cm.binary)</span><br><span class="line">        axs[0,2].imshow(train_data[len(train_data)//1000*500].reshape(28,28), cmap=cm.binary)</span><br><span class="line">        axs[0,3].imshow(train_data[len(train_data)//1000*999].reshape(28,28), cmap=cm.binary)</span><br><span class="line">        </span><br><span class="line">        # 展示图片</span><br><span class="line">        plt.show()</span><br><span class="line">    except:</span><br><span class="line">        print (&quot;No X server, skipping drawing&quot;)</span><br><span class="line"></span><br><span class="line">train_data = augTrainData(train_data,1)</span><br></pre></td></tr></table></figure></p>
<h2 id="训练效果"><a href="#训练效果" class="headerlink" title="训练效果"></a>训练效果</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Before augmentaion: (32000, 28, 28, 1), (32000, 10)</span><br><span class="line">After augmentaion: (192000, 28, 28, 1), (192000, 10)</span><br><span class="line">...</span><br><span class="line">All steps:  1920*200 = 384000</span><br><span class="line">Epoch 1/200, Step 1/384000: Learn Rate=0.001, Minibatch Loss=1778990.125, Training Accuracy=0.109999999404, Validation Accuracy=0.132499992847</span><br><span class="line">Epoch 1/200, Step 100/384000: Learn Rate=0.001, Minibatch Loss=46582.765625, Training Accuracy=0.680000007153, Validation Accuracy=0.77120000124</span><br><span class="line">Epoch 1/200, Step 200/384000: Learn Rate=0.001, Minibatch Loss=30213.3691406, Training Accuracy=0.759999990463, Validation Accuracy=0.851599991322</span><br><span class="line">...</span><br><span class="line">Epoch 120/200, Step 230300/384000: Learn Rate=0.00031381059609, Minibatch Loss=0.0, Training Accuracy=1.0, Validation Accuracy=0.992200016975</span><br><span class="line">43813 Epoch 120/200, Step 230400/384000: Learn Rate=0.00031381059609, Minibatch Loss=0.0, Training Accuracy=1.0, Validation Accuracy=0.992699980736</span><br><span class="line">43814 Epoch 121/200, Step 230500/384000: Learn Rate=0.000282429536481, Minibatch Loss=0.0, Training Accuracy=1.0, Validation Accuracy=0.992200016975</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
<p>以上</p>

      
    </div>

    

    
    
    

    

    
      
    
    

    

    <footer class="post-footer">

      
        <div class="post-tags">
         <br>
         <br>
<!--  Dorian Removed Start    
         
            <a href="/tags/Algorithm/" rel="tag"># Algorithm</a>
         
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
         
            <a href="/tags/Computer-Vision/" rel="tag"># Computer Vision</a>
         
            <a href="/tags/TensorFlow/" rel="tag"># TensorFlow</a>
         
       Dorian Removed End -->
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/04/25/CNN/" rel="next" title="CNN 卷积神经网络">
                <i class="fa fa-chevron-left"></i> CNN 卷积神经网络
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/05/11/Binary-Classification-by-RandomForest/" rel="prev" title="Binary Classification by RandomForest 基于随机森林的二分类问题实践">
                Binary Classification by RandomForest 基于随机森林的二分类问题实践 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>


  </div>


          </div>
          

  
    <div class="comments" id="gitalk-container">
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/uploads/eric_clapton.jpg" alt="Dorian Zi">
            
              <p class="site-author-name" itemprop="name">Dorian Zi</p>
              <div class="site-description motion-element" itemprop="description"></div>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">52</span>
                    <span class="site-state-item-name">posts</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  
                    
                      <a href="/categories/">
                    
                  
                    
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">2</span>
                    <span class="site-state-item-name">categories</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  
                    
                      <a href="/tags/">
                    
                  
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">16</span>
                    <span class="site-state-item-name">tags</span>
                  </a>
                </div>
              
            </nav>
          

          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://github.com/dorianzi" title="GitHub &rarr; https://github.com/dorianzi" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://kaggle.com/dorianzi" title="Kaggle &rarr; https://kaggle.com/dorianzi" rel="noopener" target="_blank"><i class="fa fa-fw fa-list-alt"></i>Kaggle</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://xiami.com/artist/mf8ydg642ef" title="Xiami &rarr; https://xiami.com/artist/mf8ydg642ef" rel="noopener" target="_blank"><i class="fa fa-fw fa-music"></i>Xiami</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://music.163.com/#/album?id=3080421" title="Netease &rarr; https://music.163.com/#/album?id=3080421" rel="noopener" target="_blank"><i class="fa fa-fw fa-headphones"></i>Netease</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://facebook.com/profile.php?id=100008679135728" title="FB Page &rarr; https://facebook.com/profile.php?id=100008679135728" rel="noopener" target="_blank"><i class="fa fa-fw fa-facebook"></i>FB Page</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://instagram.com/dorian.zi/" title="Instagram &rarr; https://instagram.com/dorian.zi/" rel="noopener" target="_blank"><i class="fa fa-fw fa-instagram"></i>Instagram</a>
                </span>
              
                <span class="links-of-author-item">
                  
                  
                    
                  
                  
                    
                  
                  <a href="https://linkedin.com/in/dorian-zi-7620b6127/" title="Linkedin &rarr; https://linkedin.com/in/dorian-zi-7620b6127/" rel="noopener" target="_blank"><i class="fa fa-fw fa-linkedin"></i>Linkedin</a>
                </span>
              
            </div>
          

          <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=481876106&auto=1&height=66"></iframe>

          

          
          

          
            
          
          

        </div>
      </div>

      
      <!--noindex-->
        <div class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
            
            
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#数据集"><span class="nav-number">1.</span> <span class="nav-text">数据集</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网络结构"><span class="nav-number">2.</span> <span class="nav-text">网络结构</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#代码解析"><span class="nav-number">3.</span> <span class="nav-text">代码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#安装TensorFlow"><span class="nav-number">3.1.</span> <span class="nav-text">安装TensorFlow</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#获得数据集"><span class="nav-number">3.2.</span> <span class="nav-text">获得数据集</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#从TensorFlow获取"><span class="nav-number">3.2.1.</span> <span class="nav-text">从TensorFlow获取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#从Kaggle比赛项目获取"><span class="nav-number">3.2.2.</span> <span class="nav-text">从Kaggle比赛项目获取</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#代码解析-1"><span class="nav-number">3.2.3.</span> <span class="nav-text">代码解析</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#pandas中的数据结构"><span class="nav-number">3.2.3.1.</span> <span class="nav-text">pandas中的数据结构</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#多维数据在numpy-ndarray中的表示"><span class="nav-number">3.2.3.2.</span> <span class="nav-text">多维数据在numpy.ndarray中的表示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#独热编码"><span class="nav-number">3.2.3.3.</span> <span class="nav-text">独热编码</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#验证集分割"><span class="nav-number">3.2.4.</span> <span class="nav-text">验证集分割</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#使用TensorFlow构建CNN网络"><span class="nav-number">3.3.</span> <span class="nav-text">使用TensorFlow构建CNN网络</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#代码讲解"><span class="nav-number">3.3.1.</span> <span class="nav-text">代码讲解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-nn-conv2d函数"><span class="nav-number">3.3.1.1.</span> <span class="nav-text">tf.nn.conv2d函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-nn-bias-add函数"><span class="nav-number">3.3.1.2.</span> <span class="nav-text">tf.nn.bias_add函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-nn-max-pool函数"><span class="nav-number">3.3.1.3.</span> <span class="nav-text">tf.nn.max_pool函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-nn-softmax函数"><span class="nav-number">3.3.1.4.</span> <span class="nav-text">tf.nn.softmax函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-nn-softmax-cross-entropy-with-logits-v2函数"><span class="nav-number">3.3.1.5.</span> <span class="nav-text">tf.nn.softmax_cross_entropy_with_logits_v2函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练和预测"><span class="nav-number">3.4.</span> <span class="nav-text">训练和预测</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#代码讲解-1"><span class="nav-number">3.4.1.</span> <span class="nav-text">代码讲解</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#sess-run函数"><span class="nav-number">3.4.1.1.</span> <span class="nav-text">sess.run函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#tf-train-shuffle-batch函数"><span class="nav-number">3.4.1.2.</span> <span class="nav-text">tf.train.shuffle_batch函数</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#数据增强"><span class="nav-number">3.5.</span> <span class="nav-text">数据增强</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练效果"><span class="nav-number">3.6.</span> <span class="nav-text">训练效果</span></a></li></ol></li></ol></div>
            

          </div>
        </div>
      <!--/noindex-->
      

      

    </div>
  </aside>
  


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2020</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Dorian Zi</span>

  

  
</div>


  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> v3.8.0</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme – <a href="https://theme-next.org" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a> v7.0.1</div>




        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="post-meta-item-icon">
      <i class="fa fa-user"></i>
    </span>
    <span class="site-uv" title="Total Visitors">
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="post-meta-divider">|</span>
  

  
    <span class="post-meta-item-icon">
      <i class="fa fa-eye"></i>
    </span>
    <span class="site-pv" title="Total Views">
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

    

    
  </div>

  

<script>
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  <script src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>


  


  <script src="/js/src/utils.js?v=7.0.1"></script>

  <script src="/js/src/motion.js?v=7.0.1"></script>



  
  


  <script src="/js/src/affix.js?v=7.0.1"></script>

  <script src="/js/src/schemes/pisces.js?v=7.0.1"></script>




  
  <script src="/js/src/scrollspy.js?v=7.0.1"></script>
<script src="/js/src/post-details.js?v=7.0.1"></script>



  


  <script src="/js/src/next-boot.js?v=7.0.1"></script>


  

  

  

  


  
    

<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>



<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.css">



<script src="//cdn.jsdelivr.net/npm/js-md5@0.7.3/src/md5.min.js"></script>

<script>
  var gitalk = new Gitalk({
    clientID: '5b4b5d838e55b91b3713',
    clientSecret: 'ca4bfc7fee3940ef0896565d06b76890fd29ce40',
    repo: 'DorianZi.github.io',
    owner: 'DorianZi',
    admin: ['DorianZi'],
    id: md5(location.pathname),
    
      language: window.navigator.language || window.navigator.userLanguage,
    
    distractionFreeMode: 'true'
  });
  gitalk.render('gitalk-container');
</script>

  


  



  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=7.0.1"></script>



  

  

  

  

  

  

  

  

  

  

  

  

  

  

</body>
</html>
